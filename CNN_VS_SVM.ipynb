{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyPQsqOpPNwPpYA1x+5wVN+7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abrham17/SVM_VS_SOFTMAX/blob/main/CNN_VS_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **importing libraries**\n",
        "\n",
        "\n",
        "*   pytorch for CNN base model creating , optimization algorithms , datasets and dataloders\n",
        "*   sklearn for support vector component , and acccuracy measure\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P0BBRgWhPyyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVC is a sickit learn implementatio of svm it supports:-\n",
        "\n",
        "\n",
        "*   C parameter\n",
        "*   kernel options(linear , rbf , poly)\n",
        "*   multi class classification via internal one to one classification\n",
        "\n",
        "for k classes it trains K(K-1)/2 classifiers\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Aq8Z-60kSy3p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QG1JpPdA-xnr"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN model MNIST classification\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yhWT6-rPV16K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple Convolutional Neural Network (CNN) architecture for MNIST digit classification.\n",
        "\n",
        "    This network is designed for grayscale handwritten digit images (28x28) and outputs\n",
        "    class logits for a given number of categories (default: 10 for MNIST digits 0–9).\n",
        "    It can also be used as a generic feature extractor by using the `extract_features` method.\n",
        "\n",
        "    Architecture:\n",
        "        Input: (batch_size, 1, 28, 28)\n",
        "        Layer 1:\n",
        "            - Conv2d(1 → 32 filters, kernel_size=3, padding=1)\n",
        "            - ReLU activation\n",
        "            - MaxPool2d(kernel_size=2, stride=2) → output shape: (batch_size, 32, 14, 14)\n",
        "        Layer 2:\n",
        "            - Conv2d(32 → 64 filters, kernel_size=3, padding=1)\n",
        "            - ReLU activation\n",
        "            - MaxPool2d(kernel_size=2, stride=2) → output shape: (batch_size, 64, 7, 7)\n",
        "        Fully Connected Layers:\n",
        "            - Flatten → shape: (batch_size, 64*7*7)\n",
        "            - Linear(64*7*7 → 128)\n",
        "            - ReLU activation\n",
        "            - Linear(128 → num_classes) → produces raw logits\n",
        "\n",
        "    Attributes:\n",
        "        conv1 (nn.Conv2d): First convolutional layer mapping 1 input channel to 32 feature maps.\n",
        "        conv2 (nn.Conv2d): Second convolutional layer mapping 32 feature maps to 64 feature maps.\n",
        "        pool (nn.MaxPool2d): Max pooling operation with kernel size 2 and stride 2.\n",
        "        fc1 (nn.Linear): First fully connected layer mapping flattened features to 128 hidden units.\n",
        "        fc2 (nn.Linear): Output fully connected layer mapping 128 hidden units to `num_classes` logits.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int): Number of output classes. Defaults to 10.\n",
        "\n",
        "    Methods:\n",
        "        forward(x):\n",
        "            Performs the full forward pass of the CNN from input images to final logits.\n",
        "            Input: Tensor of shape (batch_size, 1, 28, 28)\n",
        "            Output: Tensor of shape (batch_size, num_classes) containing raw logits.\n",
        "\n",
        "        extract_features(x):\n",
        "            Performs a partial forward pass to extract deep features before the final classification layer.\n",
        "            This is useful for using CNN as a feature extractor for other models (e.g., SVM, kNN).\n",
        "            Input: Tensor of shape (batch_size, 1, 28, 28)\n",
        "            Output: Tensor of shape (batch_size, 128) containing high-level features.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)  # logits\n",
        "        return x\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "TbPKp_gA_ng_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data initalization\n"
      ],
      "metadata": {
        "id": "z_7AGZF2ZY3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preparation for MNIST**\n",
        "- Convert images from NumPy arrays to PyTorch tensors.\n",
        "- Normalize pixel values with mean 0.1307 and std 0.3081.\n",
        "- Load MNIST training and test datasets from torchvision.\n",
        "- Apply transformations to both sets.\n",
        "- Create DataLoaders with batch size 64 (shuffle train set)."
      ],
      "metadata": {
        "id": "3M9--oarZdXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "CFcxfg5n_w-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training loop\n",
        "- device intialization if cuda is available use it else use cpu\n",
        "- used Adam optimizer with lr of 0.01\n",
        "- loss is cross entrophy loss becuase we a working on multi class classification so cross entrophy applies softmax before working on the loss\n",
        "- trianing loop with 3 epochs"
      ],
      "metadata": {
        "id": "9_1hWTQUa-s0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 3\n",
        "start = time.time()\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "end = time.time()\n",
        "print(f\"training time {end-start}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGumPDYC_xze",
        "outputId": "74cc2fb9-5d9d-435b-cfb9-34c5d1809121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 0.1134\n",
            "Epoch [2/3], Loss: 0.2229\n",
            "Epoch [3/3], Loss: 0.0492\n",
            "training time 294.05833625793457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# evaluation of CNN model with softmax\n"
      ],
      "metadata": {
        "id": "Hmsm5tapccEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "print(f\"CNN + Softmax Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9UPkEEy_1WW",
        "outputId": "44b54c7d-ae32-4bed-f390-a4f1e7838ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN + Softmax Accuracy: 98.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## feature extraction for SVM\n",
        "\n",
        "- Feature extraction using CNN's extract features method then vertical stacking the train_features and test features"
      ],
      "metadata": {
        "id": "kGxlOrcvci7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "# Extract train features\n",
        "train_features, train_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        feats = model.extract_features(images)\n",
        "        train_features.append(feats.cpu().numpy())\n",
        "        train_labels.append(labels.numpy())\n",
        "\n",
        "train_features = np.vstack(train_features)\n",
        "train_labels = np.hstack(train_labels)\n",
        "\n",
        "# Extract test features\n",
        "test_features, test_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        feats = model.extract_features(images)\n",
        "        test_features.append(feats.cpu().numpy())\n",
        "        test_labels.append(labels.numpy())\n",
        "\n",
        "test_features = np.vstack(test_features)\n",
        "test_labels = np.hstack(test_labels)\n"
      ],
      "metadata": {
        "id": "bF_y0Vta_38k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using SVM from sklearn's SVM.SVC\n",
        "- initalizing the SVC model from sklearn using linear kernel if needed the kernel can be changed to rbf and poly\n",
        "- training the SVC with the extracted train features\n",
        "- at last predicting and measuring the SVC model"
      ],
      "metadata": {
        "id": "f9ZTXPJ9iCx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "svm_clf = SVC(kernel='linear')\n",
        "descion = svm_clf.fit(train_features, train_labels)\n",
        "end = time.time()\n",
        "print(f\"training time {end-start}\")\n",
        "svm_preds = svm_clf.predict(test_features)\n",
        "svm_acc = accuracy_score(test_labels, svm_preds)\n",
        "\n",
        "print(f\"CNN (feature extractor) + SVM Accuracy: {svm_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99hxggfy_9hA",
        "outputId": "f90a13e9-f795-4f08-de71-2f15ffad5a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training time 7.123582601547241\n",
            "CNN (feature extractor) + SVM Accuracy: 99.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1c548d9"
      },
      "source": [
        "## Get cnn classifier output\n",
        "\n",
        "Obtain the output of the CNN before the final softmax layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e255c02"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "n_samples = 5000\n",
        "subset_indices = np.arange(n_samples)\n",
        "subset_images = []\n",
        "subset_labels = []\n",
        "\n",
        "# Assuming train_dataset is a standard PyTorch Dataset\n",
        "for i in subset_indices:\n",
        "    image, label = train_dataset[i]\n",
        "    subset_images.append(image)\n",
        "    subset_labels.append(label)\n",
        "\n",
        "# Stack images and convert to tensor\n",
        "subset_images_tensor = torch.stack(subset_images).to(device)\n",
        "subset_labels_tensor = torch.tensor(subset_labels).to(device)\n",
        "\n",
        "\n",
        "# Get CNN outputs before softmax\n",
        "with torch.no_grad():\n",
        "    cnn_outputs_subset = model(subset_images_tensor).cpu().numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bc6f765"
      },
      "source": [
        "## Apply dimensionality reduction to cnn output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cf5fa03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "2541625c-661c-4a98-af34-46b48093b417"
      },
      "source": [
        "tsne_cnn = TSNE(n_components=2, random_state=42, n_jobs=-1)\n",
        "cnn_outputs_2d = tsne_cnn.fit_transform(cnn_outputs_subset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'TSNE' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3045096326.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtsne_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcnn_outputs_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_outputs_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TSNE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55ef79dc"
      },
      "source": [
        "## Visualize the cnn classifier output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c39be627"
      },
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "scatter = plt.scatter(cnn_outputs_2d[:, 0], cnn_outputs_2d[:, 1], c=subset_labels, cmap='tab10', s=10)\n",
        "plt.title(\"t-SNE Visualization of CNN Outputs\")\n",
        "plt.colorbar(scatter, label=\"Digit Label\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d224ddea"
      },
      "source": [
        "## Get svm classifier decision function output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "396c41fc"
      },
      "source": [
        "svm_decision_subset = svm_clf.decision_function(train_features_subset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17d7995e"
      },
      "source": [
        "## Apply dimensionality reduction to svm output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c26e19fc"
      },
      "source": [
        "tsne_svm_decision = TSNE(n_components=2, random_state=42, n_jobs=-1)\n",
        "svm_decision_2d = tsne_svm_decision.fit_transform(svm_decision_subset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5e96cef"
      },
      "source": [
        "## Visualize the svm classifier output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ccbef1c"
      },
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "scatter = plt.scatter(svm_decision_2d[:, 0], svm_decision_2d[:, 1], c=subset_labels, cmap='tab10', s=10)\n",
        "plt.title(\"t-SNE Visualization of SVM Decision Function Outputs\")\n",
        "plt.colorbar(scatter, label=\"Digit Label\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2567fe4"
      },
      "source": [
        "## Visualize svm decision boundary\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95c1d371"
      },
      "source": [
        "# Train a new SVM on the 2D t-SNE features\n",
        "svm_clf_2d = SVC(kernel='linear')\n",
        "svm_clf_2d.fit(train_features_2d, train_labels_subset)\n",
        "\n",
        "# Create a meshgrid\n",
        "x_min, x_max = train_features_2d[:, 0].min() - 1, train_features_2d[:, 0].max() + 1\n",
        "y_min, y_max = train_features_2d[:, 1].min() - 1, train_features_2d[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
        "                     np.arange(y_min, y_max, 0.1))\n",
        "\n",
        "# Predict decision function values for the meshgrid\n",
        "Z = svm_clf_2d.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "# Reshape the decision function output for contour plotting\n",
        "# For multi-class with decision_function, Z will have shape (n_samples, n_classes)\n",
        "# We need to choose how to represent the boundary. A common way is to show boundaries\n",
        "# between all pairs of classes, but for a single contour plot, we can visualize\n",
        "# the boundary of one-vs-rest or the predicted class.\n",
        "# Let's visualize the predicted class for simplicity in the contour plot.\n",
        "Z = svm_clf_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "\n",
        "# Plot the contour of the decision boundary\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "\n",
        "# Overlay the scatter plot of the data points\n",
        "scatter = plt.scatter(train_features_2d[:, 0], train_features_2d[:, 1], c=train_labels_subset, cmap='tab10', s=10, edgecolors='k')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title(\"SVM Decision Boundary on t-SNE Reduced Features\")\n",
        "plt.xlabel(\"t-SNE Component 1\")\n",
        "plt.ylabel(\"t-SNE Component 2\")\n",
        "plt.colorbar(scatter, label=\"Digit Label\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}